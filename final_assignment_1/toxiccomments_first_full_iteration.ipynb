{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toxic comments\n",
    "\n",
    "This notebook takes you though a complete iteration of Machine Learning Assignment 1 - Toxic comments. The assignment details (including links to download the data) can be found [here](https://docs.google.com/document/d/1WGYw99e5q6j5V0Zrf2HveagU6URt_kVvdR8B9HYQ99E/edit?usp=sharing). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all imports and magic commands\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from my_measures import BinaryClassificationPerformance\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTANT!!! Make sure you are using `BinaryClassificationPerformance` v1.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class BinaryClassificationPerformance in module my_measures:\n",
      "\n",
      "class BinaryClassificationPerformance(builtins.object)\n",
      " |  BinaryClassificationPerformance(predictions, labels, desc, probabilities=None)\n",
      " |  \n",
      " |  Performance measures to evaluate the fit of a binary classification model, v1.02\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, predictions, labels, desc, probabilities=None)\n",
      " |      Initialize attributes: predictions-vector of predicted values for Y, labels-vector of labels for Y\n",
      " |  \n",
      " |  compute_measures(self)\n",
      " |      Compute performance measures defined by Flach p. 57\n",
      " |  \n",
      " |  img_indices(self)\n",
      " |      Get the indices of true and false positives to be able to locate the corresponding images in a list of image names\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(BinaryClassificationPerformance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for feature building and extraction on natural language data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that takes raw data and completes all preprocessing required before model fits\n",
    "def process_raw_data(fn, my_random_seed, test=False):\n",
    "    # read and summarize data\n",
    "    toxic_data = pd.read_csv(fn)\n",
    "    if (not test):\n",
    "        # add an indicator for any toxic, severe toxic, obscene, threat, insult, or indentity hate\n",
    "        toxic_data['any_toxic'] = (toxic_data['toxic'] + toxic_data['severe_toxic'] + toxic_data['obscene'] + toxic_data['threat'] + toxic_data['insult'] + toxic_data['identity_hate'] > 0)\n",
    "    print(\"toxic_data is:\", type(toxic_data))\n",
    "    print(\"toxic_data has\", toxic_data.shape[0], \"rows and\", toxic_data.shape[1], \"columns\", \"\\n\")\n",
    "    print(\"the data types for each of the columns in toxic_data:\")\n",
    "    print(toxic_data.dtypes, \"\\n\")\n",
    "    print(\"the first 10 rows in toxic_data:\")\n",
    "    print(toxic_data.head(5))\n",
    "    if (not test):\n",
    "        print(\"The rate of 'toxic' Wikipedia comments in the dataset: \")\n",
    "        print(toxic_data['any_toxic'].mean())\n",
    "\n",
    "    # vectorize Bag of Words from review text; as sparse matrix\n",
    "    if (not test): # fit_transform()\n",
    "        hv = HashingVectorizer(n_features= 2**22, alternate_sign=False) #z.B. 2**22\n",
    "        X_hv = hv.fit_transform(toxic_data.comment_text)\n",
    "        fitted_transformations.append(hv)\n",
    "        print(\"Shape of HashingVectorizer X:\")\n",
    "        print(X_hv.shape)\n",
    "    else: # transform() \n",
    "        X_hv = fitted_transformations[0].transform(toxic_data.comment_text)\n",
    "        print(\"Shape of HashingVectorizer X:\")\n",
    "        print(X_hv.shape)\n",
    "    \n",
    "    # http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html\n",
    "    if (not test):\n",
    "        transformer = TfidfTransformer()\n",
    "        X_tfidf = transformer.fit_transform(X_hv)\n",
    "        fitted_transformations.append(transformer)\n",
    "    else:\n",
    "        X_tfidf = fitted_transformations[1].transform(X_hv)\n",
    "    \n",
    "    # create additional quantitative features\n",
    "    # features from Amazon.csv to add to feature set\n",
    "    toxic_data['word_count'] = toxic_data['comment_text'].str.split(' ').str.len()\n",
    "    toxic_data['punc_count'] = toxic_data['comment_text'].str.count(\"\\.\")\n",
    "\n",
    "    X_quant_features = toxic_data[[\"word_count\", \"punc_count\"]]\n",
    "    print(\"Look at a few rows of the new quantitative features: \")\n",
    "    print(X_quant_features.head(10))\n",
    "    \n",
    "    # Combine all quantitative features into a single sparse matrix\n",
    "    X_quant_features_csr = csr_matrix(X_quant_features)\n",
    "    X_combined = hstack([X_tfidf, X_quant_features_csr])\n",
    "    X_matrix = csr_matrix(X_combined) # convert to sparse matrix\n",
    "    print(\"Size of combined bag of words and new quantitative variables matrix:\")\n",
    "    print(X_matrix.shape)\n",
    "    \n",
    "    # Create `X`, scaled matrix of features\n",
    "    # feature scaling\n",
    "    if (not test):\n",
    "        sc = StandardScaler(with_mean=False)\n",
    "        X = sc.fit_transform(X_matrix)\n",
    "        fitted_transformations.append(sc)\n",
    "        print(X.shape)\n",
    "        y = toxic_data['any_toxic']\n",
    "    else:\n",
    "        X = fitted_transformations[2].transform(X_matrix)\n",
    "        print(X.shape)\n",
    "    \n",
    "    # Create Training and Test Sets\n",
    "    # enter an integer for the random_state parameter; any integer will work\n",
    "    if (test):\n",
    "        X_submission_test = X\n",
    "        print(\"Shape of X_test for submission:\")\n",
    "        print(X_submission_test.shape)\n",
    "        print('SUCCESS!')\n",
    "        return(toxic_data, X_submission_test)\n",
    "    else: \n",
    "        X_train, X_test, y_train, y_test, X_raw_train, X_raw_test = train_test_split(X, y, toxic_data, test_size=0.2, random_state=my_random_seed)\n",
    "        print(\"Shape of X_train and X_test:\")\n",
    "        print(X_train.shape)\n",
    "        print(X_test.shape)\n",
    "        print(\"Shape of y_train and y_test:\")\n",
    "        print(y_train.shape)\n",
    "        print(y_test.shape)\n",
    "        print(\"Shape of X_raw_train and X_raw_test:\")\n",
    "        print(X_raw_train.shape)\n",
    "        print(X_raw_test.shape)\n",
    "        print('SUCCESS!')\n",
    "        return(X_train, X_test, y_train, y_test, X_raw_train, X_raw_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create training and test sets from function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic_data is: <class 'pandas.core.frame.DataFrame'>\n",
      "toxic_data has 159571 rows and 9 columns \n",
      "\n",
      "the data types for each of the columns in toxic_data:\n",
      "id               object\n",
      "comment_text     object\n",
      "toxic             int64\n",
      "severe_toxic      int64\n",
      "obscene           int64\n",
      "threat            int64\n",
      "insult            int64\n",
      "identity_hate     int64\n",
      "any_toxic          bool\n",
      "dtype: object \n",
      "\n",
      "the first 10 rows in toxic_data:\n",
      "                 id                                       comment_text  toxic  \\\n",
      "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
      "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
      "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
      "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
      "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
      "\n",
      "   severe_toxic  obscene  threat  insult  identity_hate  any_toxic  \n",
      "0             0        0       0       0              0      False  \n",
      "1             0        0       0       0              0      False  \n",
      "2             0        0       0       0              0      False  \n",
      "3             0        0       0       0              0      False  \n",
      "4             0        0       0       0              0      False  \n",
      "The rate of 'toxic' Wikipedia comments in the dataset: \n",
      "0.10167887648758234\n",
      "Shape of HashingVectorizer X:\n",
      "(159571, 4194304)\n",
      "Look at a few rows of the new quantitative features: \n",
      "   word_count  punc_count\n",
      "0          42           5\n",
      "1          18           2\n",
      "2          42           3\n",
      "3         112           3\n",
      "4          13           1\n",
      "5          12           1\n",
      "6           8           0\n",
      "7          21           2\n",
      "8          83           7\n",
      "9          12           0\n",
      "Size of combined bag of words and new quantitative variables matrix:\n",
      "(159571, 4194306)\n",
      "(159571, 4194306)\n",
      "Shape of X_train and X_test:\n",
      "(127656, 4194306)\n",
      "(31915, 4194306)\n",
      "Shape of y_train and y_test:\n",
      "(127656,)\n",
      "(31915,)\n",
      "Shape of X_raw_train and X_raw_test:\n",
      "(127656, 11)\n",
      "(31915, 11)\n",
      "SUCCESS!\n",
      "Number of fits stored in `fitted_transformations` list: \n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# create an empty list to store any use of fit_transform() to transform() later\n",
    "# it is a global list to store model and feature extraction fits\n",
    "fitted_transformations = []\n",
    "\n",
    "# CHANGE FILE PATH and my_random_seed number (any integer other than 74 will do): \n",
    "X_train, X_test, y_train, y_test, X_raw_train, X_raw_test = process_raw_data(fn = r\"C:\\Users\\miame\\Documents\\000UNI\\000PARSONS\\MACHINE LEARNING\\CODES\\ml\\final_assignment_1\\toxiccomments_train.csv\", my_random_seed=42)\n",
    "\n",
    "print(\"Number of fits stored in `fitted_transformations` list: \")\n",
    "print(len(fitted_transformations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit (and tune) Various Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL: ordinary least squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "ols = linear_model.SGDClassifier(loss=\"squared_loss\")\n",
    "ols.fit(X_train, y_train)\n",
    "\n",
    "ols_performance_train = BinaryClassificationPerformance(ols.predict(X_train), y_train, 'ols_train')\n",
    "ols_performance_train.compute_measures()\n",
    "print(ols_performance_train.performance_measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL: SVM, linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "svm = linear_model.SGDClassifier()\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "svm_performance_train = BinaryClassificationPerformance(svm.predict(X_train), y_train, 'svm_train')\n",
    "svm_performance_train.compute_measures()\n",
    "print(svm_performance_train.performance_measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL: logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "lgs = linear_model.SGDClassifier(loss='log')\n",
    "lgs.fit(X_train, y_train)\n",
    "\n",
    "lgs_performance_train = BinaryClassificationPerformance(lgs.predict(X_train), y_train, 'lgs_train')\n",
    "lgs_performance_train.compute_measures()\n",
    "print(lgs_performance_train.performance_measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL: Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nbs = MultinomialNB()\n",
    "nbs.fit(X_train, y_train)\n",
    "\n",
    "nbs_performance_train = BinaryClassificationPerformance(nbs.predict(X_train), y_train, 'nbs_train')\n",
    "nbs_performance_train.compute_measures()\n",
    "print(nbs_performance_train.performance_measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL: Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 12981, 'Neg': 114675, 'TP': 12890, 'TN': 114541, 'FP': 134, 'FN': 91, 'Accuracy': 0.9982374506486181, 'Precision': 0.9897113022113022, 'Recall': 0.9929897542562206, 'desc': 'prc_train'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "prc = linear_model.SGDClassifier(loss='perceptron')\n",
    "prc.fit(X_train, y_train)\n",
    "\n",
    "prc_performance_train = BinaryClassificationPerformance(prc.predict(X_train), y_train, 'prc_train')\n",
    "prc_performance_train.compute_measures()\n",
    "print(prc_performance_train.performance_measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL: Ridge Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "rdg = linear_model.RidgeClassifier(30000) # provide alpha value here; default is 1.0\n",
    "rdg.fit(X_train, y_train)\n",
    "\n",
    "rdg_performance_train = BinaryClassificationPerformance(rdg.predict(X_train), y_train, 'rdg_train')\n",
    "rdg_performance_train.compute_measures()\n",
    "print(rdg_performance_train.performance_measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL: Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rdf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "rdf.fit(X_train, y_train)\n",
    "\n",
    "rdf_performance_train = BinaryClassificationPerformance(rdf.predict(X_train), y_train, 'rdf_train')\n",
    "rdf_performance_train.compute_measures()\n",
    "print(rdf_performance_train.performance_measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC plot to compare performance of various models and fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fits = [ols_performance_train, svm_performance_train, lgs_performance_train, nbs_performance_train, prc_performance_train, rdg_performance_train, rdf_performance_train]\n",
    "\n",
    "for fit in fits:\n",
    "    plt.plot(fit.performance_measures['FP'] / fit.performance_measures['Neg'], \n",
    "             fit.performance_measures['TP'] / fit.performance_measures['Pos'], 'bo')\n",
    "    plt.text(fit.performance_measures['FP'] / fit.performance_measures['Neg'], \n",
    "             fit.performance_measures['TP'] / fit.performance_measures['Pos'], fit.desc)\n",
    "plt.axis([0, 1, 0, 1])\n",
    "plt.title('ROC plot: test set')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### looking at reviews based on their classification\n",
    "\n",
    "Let's say we decide that Ordinary Least Squares (OLS) Regression is the best model for generalization. Let's take a look at some of the reviews and try to make a (subjective) determination of whether it's generalizing well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### let's look at some false positives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdg_predictions = rdg.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# false positives\n",
    "\n",
    "print(\"Examples of false positives:\")\n",
    "\n",
    "import random, time\n",
    "\n",
    "for i in range(0, len(rdg_predictions)):\n",
    "    if (rdg_predictions[i] == 1):\n",
    "        if (X_raw_train.iloc[i]['any_toxic'] == 0):\n",
    "            if (random.uniform(0, 1) < 0.05): # to print only 5% of the false positives\n",
    "                print(i)\n",
    "                print(X_raw_train.iloc[i]['comment_text'])\n",
    "                print('* * * * * * * * * ')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# <span style=\"color:red\">WARNING: Don't look at test set performance too much!</span>\n",
    "\n",
    "---\n",
    "\n",
    "The following cells show performance on your test set. Do not look at this too often! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at performance on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL: ordinary least squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_performance_test = BinaryClassificationPerformance(ols.predict(X_test), y_test, 'ols_test')\n",
    "ols_performance_test.compute_measures()\n",
    "print(ols_performance_test.performance_measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL: SVM, linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_performance_test = BinaryClassificationPerformance(svm.predict(X_test), y_test, 'svm_test')\n",
    "svm_performance_test.compute_measures()\n",
    "print(svm_performance_test.performance_measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL: logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgs_performance_test = BinaryClassificationPerformance(lgs.predict(X_test), y_test, 'lgs_test')\n",
    "lgs_performance_test.compute_measures()\n",
    "print(lgs_performance_test.performance_measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL: Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbs_performance_test = BinaryClassificationPerformance(nbs.predict(X_test), y_test, 'nbs_test')\n",
    "nbs_performance_test.compute_measures()\n",
    "print(nbs_performance_test.performance_measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL: Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 3244, 'Neg': 28671, 'TP': 2118, 'TN': 27264, 'FP': 1407, 'FN': 1126, 'Accuracy': 0.9206329312235626, 'Precision': 0.6008510638297873, 'Recall': 0.6528976572133169, 'desc': 'prc_test'}\n"
     ]
    }
   ],
   "source": [
    "prc_performance_test = BinaryClassificationPerformance(prc.predict(X_test), y_test, 'prc_test')\n",
    "prc_performance_test.compute_measures()\n",
    "print(prc_performance_test.performance_measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL: Ridge Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdg_performance_test = BinaryClassificationPerformance(rdg.predict(X_test), y_test, 'rdg_test')\n",
    "rdg_performance_test.compute_measures()\n",
    "print(rdg_performance_test.performance_measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL: Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf_performance_test = BinaryClassificationPerformance(rdf.predict(X_test), y_test, 'rdf_test')\n",
    "rdf_performance_test.compute_measures()\n",
    "print(rdf_performance_test.performance_measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC plot to compare performance of various models and fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fits = [prc_performance_test, prc_performance_train]\n",
    "\n",
    "for fit in fits:\n",
    "    plt.plot(fit.performance_measures['FP'] / fit.performance_measures['Neg'], \n",
    "             fit.performance_measures['TP'] / fit.performance_measures['Pos'], 'bo')\n",
    "    plt.text(fit.performance_measures['FP'] / fit.performance_measures['Neg'], \n",
    "             fit.performance_measures['TP'] / fit.performance_measures['Pos'], fit.desc)\n",
    "plt.axis([0, 1, 0, 1])\n",
    "plt.title('ROC plot: test set')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# <span style=\"color:red\">SUBMISSION</span>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic_data is: <class 'pandas.core.frame.DataFrame'>\n",
      "toxic_data has 153164 rows and 2 columns \n",
      "\n",
      "the data types for each of the columns in toxic_data:\n",
      "id              object\n",
      "comment_text    object\n",
      "dtype: object \n",
      "\n",
      "the first 10 rows in toxic_data:\n",
      "                 id                                       comment_text\n",
      "0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...\n",
      "1  0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...\n",
      "2  00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...\n",
      "3  00017563c3f7919a  :If you have a look back at the source, the in...\n",
      "4  00017695ad8997eb          I don't anonymously edit articles at all.\n",
      "Shape of HashingVectorizer X:\n",
      "(153164, 4194304)\n",
      "Look at a few rows of the new quantitative features: \n",
      "   word_count  punc_count\n",
      "0          72          10\n",
      "1          13           1\n",
      "2          16           0\n",
      "3          38           3\n",
      "4           7           1\n",
      "5          16           2\n",
      "6          31           4\n",
      "7           6           1\n",
      "8         109           9\n",
      "9          41           0\n",
      "Size of combined bag of words and new quantitative variables matrix:\n",
      "(153164, 4194306)\n",
      "(153164, 4194306)\n",
      "Shape of X_test for submission:\n",
      "(153164, 4194306)\n",
      "SUCCESS!\n",
      "Number of rows in the submission test set (should be 153,164): \n"
     ]
    }
   ],
   "source": [
    "# read in test data for submission\n",
    "# CHANGE FILE PATH and my_random_seed number (any integer other than 74 will do): \n",
    "raw_data, X_test_submission = process_raw_data(fn = r\"C:\\Users\\miame\\Documents\\000UNI\\000PARSONS\\MACHINE LEARNING\\CODES\\ml\\final_assignment_1\\toxiccomments_test.csv\", my_random_seed=42, test=True)\n",
    "print(\"Number of rows in the submission test set (should be 153,164): \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Choose a <span style=\"color:red\">*single*</span> model for your submission. In this code, I am choosing the Ordinary Least Squares model fit, which is in the `ols` object. But you should choose the model that is performing the best for you! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20978167193335248\n"
     ]
    }
   ],
   "source": [
    "# store the id from the raw data\n",
    "my_submission = pd.DataFrame(raw_data[\"id\"])\n",
    "# concatenate predictions to the id\n",
    "my_submission[\"prediction\"] = prc.predict(X_test_submission)\n",
    "# look at the proportion of positive predictions\n",
    "print(my_submission['prediction'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>word_count</th>\n",
       "      <th>punc_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n",
       "      <td>72</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>== From RfC == \\n\\n The title is fine as it is...</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>:If you have a look back at the source, the in...</td>\n",
       "      <td>38</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>I don't anonymously edit articles at all.</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  \\\n",
       "0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...   \n",
       "1  0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...   \n",
       "2  00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...   \n",
       "3  00017563c3f7919a  :If you have a look back at the source, the in...   \n",
       "4  00017695ad8997eb          I don't anonymously edit articles at all.   \n",
       "\n",
       "   word_count  punc_count  \n",
       "0          72          10  \n",
       "1          13           1  \n",
       "2          16           0  \n",
       "3          38           3  \n",
       "4           7           1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  prediction\n",
       "0  00001cee341fdb12        True\n",
       "1  0000247867823ef7       False\n",
       "2  00013b17ad220c46       False\n",
       "3  00017563c3f7919a       False\n",
       "4  00017695ad8997eb       False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153164, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export submission file as pdf\n",
    "# CHANGE FILE PATH: \n",
    "my_submission.to_csv(\"C:\\\\Users\\\\miame\\\\Documents\\\\000UNI\\\\000PARSONS\\\\MACHINE LEARNING\\\\CODES\\\\ml\\\\final_assignment_1\\\\toxiccomments_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit to Canvas: 1) the CSV file that was written in the previous cell and 2) the url to the repository (GitHub or other) that contains your code and documentation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
